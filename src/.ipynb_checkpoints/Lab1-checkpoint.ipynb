{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSift(img):\n",
    "    gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    kp = sift.detect(gray,None)\n",
    "    kp,des = sift.compute(gray,kp)\n",
    "    return kp, des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurf(img):\n",
    "    surf = cv.xfeatures2d.SURF_create(400)\n",
    "    kp, des = surf.detectAndCompute(img,None)\n",
    "    return kp, des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bruteForceMatchingSIFT(des1, des2):\n",
    "    # BFMatcher with default params\n",
    "    bf = cv.BFMatcher()\n",
    "    matches = bf.knnMatch(des1,des2, k=2)\n",
    "    # Apply ratio test\n",
    "    good = 0\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good = good + 1\n",
    "    return good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flann(des1, des2):\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "    # Need to draw only good matches, so create a mask\n",
    "    matchesMask = 0\n",
    "    # ratio test as per Lowe's paper\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            matchesMask = matchesMask + 1\n",
    "    return matchesMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(img):\n",
    "    height, width = img.shape[:2]\n",
    "    return cv.resize(img,(2*width, 2*height), interpolation = cv.INTER_CUBIC)\n",
    "\n",
    "def translation(img):\n",
    "    rows,cols, color= img.shape\n",
    "    M = np.float32([[1,0,100],[0,1,50]])\n",
    "    return cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "def rotation(img):\n",
    "    rows,cols, colors = img.shape\n",
    "    # cols-1 and rows-1 are the coordinate limits.\n",
    "    M = cv.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),90,1)\n",
    "    return cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "def affine(img):\n",
    "    rows,cols,ch = img.shape\n",
    "    pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "    pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    "    M = cv.getAffineTransform(pts1,pts2)\n",
    "    return cv.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "def createTrainingSet():\n",
    "    images = [cv.imread(file) for file in glob.glob(\"../data/training/Origin/*.jpg\")]\n",
    "    n = 0\n",
    "    for image in images:\n",
    "        cv.imshow('../data/training/training/' + repr(n) + 'scaling.jpg',scaling(image))\n",
    "        cv.imwrite('../data/training/training/' + repr(n) + 'translation.jpg',translation(image))\n",
    "        cv.imwrite('../data/training/training/' + repr(n) + 'rotation.jpg',rotation(image))\n",
    "        cv.imwrite('../data/training/training/' + repr(n) + 'affine.jpg',affine(image))\n",
    "        n = n + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1015, 2, 5, 9, 5, 4, 8, 5, 5, 1, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "img1 = cv.imread('../data/training/training/0rotation.jpg',0)          # queryImage<\n",
    "images = [cv.imread(file) for file in glob.glob(\"../data/training/Origin/*.jpg\")]\n",
    "scores = [flann(getSurf(image)[1], getSurf(img1)[1]) for image in images]\n",
    "print(scores.index(max(scores)))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1():\n",
    "    for filename in os.listdir('../data/jpg2/clusters'):\n",
    "        img = cv.imread(os.path.join('../data/jpg2/clusters',filename))\n",
    "        if img is not None:\n",
    "            kp,des = getSurf(img)\n",
    "            print(filename[:-4])\n",
    "            output = open('../data/descriptors/clusters/' + filename[:-4] + '.pkl', 'wb')\n",
    "            pickle.dump(des, output)\n",
    "            output.close()\n",
    "\n",
    "    for filename in os.listdir('../data/jpg2/unknown'):\n",
    "        img = cv.imread(os.path.join('../data/jpg2/unknown',filename))\n",
    "        if img is not None:\n",
    "            kp,des = getSurf(img)\n",
    "            print(filename[:-4])\n",
    "            output = open('../data/descriptors/unknown/' + filename[:-4] + '.pkl', 'wb')\n",
    "            pickle.dump(des, output)\n",
    "            output.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_clusters_flann(clusters, des_clusters_array, des):\n",
    "    flanns = []\n",
    "    for i in range(0, len(des_clusters_array)):\n",
    "        tmp = []\n",
    "        for j in range(0, len(des_clusters_array[i])):\n",
    "#            print(flann(des_clusters_array[i][j][1], des[1]))\n",
    "            tmp.append(flann(des_clusters_array[i][j][1], des[1]))\n",
    "        flanns.append(sum(tmp)/len(tmp))\n",
    "    clusters[np.argmax(flanns)].append(int(des[0]))\n",
    "    des_clusters_array[np.argmax(flanns)].append(des)\n",
    "    return clusters, des_clusters_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2():\n",
    "    des_clusters_array = []\n",
    "    clusters = []\n",
    "    for filename in os.listdir('../data/descriptors/clusters'):\n",
    "        if (filename != '.DS_Store'):\n",
    "            pkl_file = open(os.path.join('../data/descriptors/clusters',filename), 'rb')\n",
    "            x = pickle.load(pkl_file)\n",
    "            pkl_file.close()\n",
    "            clusters.append([int(filename[:-4])])\n",
    "            des_clusters_array.append([(filename[:-4], x)])\n",
    "\n",
    "    des_unknow_array = []\n",
    "    for filename in os.listdir('../data/descriptors/unknown'):\n",
    "        if (filename != '.DS_Store'):\n",
    "            pkl_file = open(os.path.join('../data/descriptors/unknown',filename), 'rb')\n",
    "            x = pickle.load(pkl_file)\n",
    "            pkl_file.close()\n",
    "            des_unknow_array.append((filename[:-4], x))\n",
    "\n",
    "    clusters_flann = copy.deepcopy(clusters) \n",
    "    for des in des_unknow_array:\n",
    "        clusters_flann, des_clusters_array = grow_clusters_flann(clusters_flann, des_clusters_array, des)\n",
    "    print(clusters_flann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
