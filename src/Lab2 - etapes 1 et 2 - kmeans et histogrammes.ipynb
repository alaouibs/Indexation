{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation de sift et surf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de stift et surf est de trouver un ensemble de keypoints et de descripteurs qui permettent de décrire une image qu'importent les transformations que nous y faisons tel qu'une rotation ou un changement d'échelle. \n",
    "surf est une version plus rapide de stift et plus étendue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La valeur 500 permet de paramétrer l'Hessian qui permet de détecter le nombre de coin dans une image. Une plus grande valeur détecte moins de coins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSurf(img):\n",
    "    surf = cv.xfeatures2d.SURF_create(500)\n",
    "    kp, des = surf.detectAndCompute(img,None)\n",
    "    return kp, des\n",
    "\n",
    "def getSift(img):\n",
    "    gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    kp = sift.detect(gray,None)\n",
    "    kp,des = sift.compute(gray,kp)\n",
    "    return kp, des\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans chaque fonction nous récupérons la liste des keypoints et la liste des descripteurs, dans le cas de stift cela sera pour les descripteurs une liste de tableaux de taille 128 et dans le cas de surf une liste de tableaux de taille 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 1 : lecture des images et génération des descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons lire toutes les images, stocker les descripteurs de l'image et le nom de l'image pour savoir dans quelle image nous avons trouvé les descripteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131402.jpg\n",
      "131401.jpg\n",
      "131400.jpg\n",
      "131000.jpg\n",
      "133602.jpg\n",
      "131001.jpg\n",
      "133600.jpg\n",
      "133601.jpg\n",
      "138308.jpg\n",
      "138309.jpg\n",
      "133700.jpg\n",
      "138708.jpg\n",
      "131102.jpg\n",
      "133701.jpg\n",
      "131100.jpg\n",
      "133703.jpg\n",
      "133702.jpg\n",
      "131101.jpg\n",
      "138302.jpg\n",
      "133900.jpg\n",
      "138100.jpg\n",
      "138706.jpg\n",
      "138504.jpg\n",
      "138505.jpg\n",
      "138707.jpg\n",
      "138101.jpg\n",
      "133901.jpg\n",
      "138303.jpg\n",
      "138301.jpg\n",
      "138103.jpg\n",
      "138705.jpg\n",
      "138507.jpg\n",
      "138506.jpg\n",
      "138704.jpg\n",
      "138102.jpg\n",
      "138300.jpg\n",
      "138304.jpg\n",
      "130200.jpg\n",
      "138700.jpg\n",
      "138502.jpg\n",
      "138503.jpg\n",
      "138701.jpg\n",
      "130201.jpg\n",
      "138305.jpg\n",
      "130001.jpg\n",
      "138307.jpg\n",
      "138105.jpg\n",
      "138703.jpg\n",
      "138501.jpg\n",
      "138500.jpg\n",
      "138702.jpg\n",
      "138104.jpg\n",
      "138306.jpg\n",
      "130000.jpg\n",
      "138605.jpg\n",
      "134003.jpg\n",
      "138003.jpg\n",
      "138201.jpg\n",
      "138200.jpg\n",
      "138002.jpg\n",
      "133802.jpg\n",
      "134002.jpg\n",
      "138604.jpg\n",
      "134000.jpg\n",
      "133800.jpg\n",
      "138202.jpg\n",
      "138203.jpg\n",
      "138001.jpg\n",
      "133801.jpg\n",
      "134001.jpg\n",
      "138401.jpg\n",
      "138603.jpg\n",
      "130303.jpg\n",
      "130101.jpg\n",
      "130100.jpg\n",
      "138004.jpg\n",
      "130302.jpg\n",
      "138602.jpg\n",
      "138400.jpg\n",
      "138600.jpg\n",
      "130300.jpg\n",
      "138012.jpg\n",
      "130102.jpg\n",
      "130301.jpg\n",
      "138601.jpg\n"
     ]
    }
   ],
   "source": [
    "descriptors_images = []\n",
    "descriptors2 = []\n",
    "for filename in os.listdir('../data/jpg3'):\n",
    "    img = cv.imread(os.path.join('../data/jpg3',filename))\n",
    "    if img is not None:\n",
    "        print(filename)\n",
    "        kp,des = getSurf(img)\n",
    "        descriptors_images.append((filename, des))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant pour chaque image nous avons un ensemble de descripteurs, ce que nous voulons c'est tous les regrouper et pouvoir les résumer en l'appartenance à un cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4926, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors_images[2][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée une immense liste qui contient tous les descripteurs et une autre liste qui contient le nom de l'image lié au descripteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldes = []\n",
    "alldes_filename = []\n",
    "for filename, des in descriptors_images:\n",
    "    for item in des:\n",
    "        alldes.append(item)\n",
    "        alldes_filename.append(filename)\n",
    "alldes = np.array(alldes)\n",
    "alldes_filename = np.array(alldes_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['131402.jpg', '131402.jpg', '131402.jpg', ..., '138601.jpg',\n",
       "       '138601.jpg', '138601.jpg'], dtype='<U10')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldes_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 2 : k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de kmeans est de trouver k centro-ids qui permet de regrouper le datas et de façon à que les éléments d'un groupe soient très \"proches\" entre eux et très \"éloigné\" des autres groupes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "ret,label,cente = cv.kmeans(alldes, k,None,criteria,10,cv.KMEANS_RANDOM_CENTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons  la distance au centre pour chaque descripteur ainsi que leur label d'appartenance et le centroid des clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pourrait utiliser la distance au cluster pour regrouper nos descripteurs mais le label suffit. \n",
    "Comme nous pouvons le voir ici pour chaque descripteurs nous avons le numéro du label auquel il appartient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47],\n",
       "       [29],\n",
       "       [29],\n",
       "       ...,\n",
       "       [93],\n",
       "       [46],\n",
       "       [29]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = []\n",
    "for l in label:\n",
    "    lab.append(l[0])\n",
    "    \n",
    "lab = np.array(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 29, 29, ..., 93, 46, 29], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous savons également avec alldes_filename l'image auquel appartient le descripteur nous pouvons crée un dataframe qui relie le nom de l'image à un cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.vstack((alldes_filename, lab)).T, columns=['image', 'cluster']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/clusters.csv\", encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
